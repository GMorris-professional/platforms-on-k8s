# Capitulo 2 :: Desafios de una Aplicaci√≥n Cloud-Native

‚Äî
_üåç Disponible en_: [English](README.md) | [‰∏≠Êñá (Chinese)](README-zh.md) | [Portugu√™s (Portuguese)](README-pt.md) | [Espa√±ol](README-es.md) | [Êó•Êú¨Ë™û (Japanese)](README-ja.md) | [Fran√ßais](README-fr.md)

> **Nota:** Presentado por la fant√°stica comunidad de [ üåü contribuidores](https://github.com/salaboy/platforms-on-k8s/graphs/contributors) cloud-native!

En este breve tutorial, instalaremos la `Aplicaci√≥n para Conferencia` usando Helm en un Cl√∫ster Kubernetes local de KinD. 

> [!NOTA]
> Los Helm Charts se pueden publicar en repositorios de Helm Charts o tambi√©n, desde Helm 3.7, como contenedores OCI en registros de contenedores.

## Creando un cl√∫ster local con Kubernetes KinD

> [!IMPORTANTE]
> Aseg√∫rese de tener los pre-requisitos para todos los tutoriales. Puedes encontrarlos [aqu√≠](../chapter-1/README.md#pre-requisites-for-the-tutorials).

Usa el siguiente comando para crear un cl√∫ster KinD con tres nodos trabajadores y 1 nodo de Control Plane.

```shell
cat <<EOF | kind create cluster --name dev --config=-
kind: Cluster
apiVersion: kind.x-k8s.io/v1alpha4
nodes:
- role: control-plane
  kubeadmConfigPatches:
  - |
    kind: InitConfiguration
    nodeRegistration:
      kubeletExtraArgs:
        node-labels: "ingress-ready=true"
  extraPortMappings:
  - containerPort: 80
    hostPort: 80
    protocol: TCP
  - containerPort: 443
    hostPort: 443
    protocol: TCP
- role: worker
- role: worker
- role: worker
EOF

```

![3 Nodos esclavos](imgs/cluster-topology.png)

## Cargando algunas im√°genes de contenedores antes de instalar la aplicaci√≥n y otros componentes

El script `kind-load.sh` pre-carga, en otras palabras, descarga y carga las im√°genes de contenedores que utilizaremos para nuestra aplicaci√≥n en nuestro cl√∫ster KinD.

La idea aqu√≠ es optimizar el proceso para nuestro cl√∫ster, de modo que cuando instalemos la aplicaci√≥n, no tengamos que esperar m√°s de 10 minutos mientras se descargan todas las im√°genes de contenedores necesarias. Con todas las im√°genes ya precargadas en nuestro cl√∫ster KinD, la aplicaci√≥n deber√≠a comenzar en alrededor de 1 minuto, que es el tiempo necesario para que PostgreSQL, Redis y Kafka arranquen.

Ahora, carguemos las im√°genes necesarias en nuestro cl√∫ster KinD.

> [!Importante]
> Al ejecutar el script mencionado en el siguiente paso, obtendr√° todas las im√°genes requeridas y luego las cargar√° en cada nodo de su cl√∫ster KinD. Si est√° ejecutando los ejemplos en un proveedor de nube, esto podr√≠a no valer la pena, ya que los proveedores de nube con conexiones de Gigabyte a registros de contenedores podr√≠an obtener estas im√°genes en cuesti√≥n de segundos.

En su terminal, acceda al directorio `chapter-2`, y desde all√≠, ejecute el script:

```shell
./kind-load.sh
```

> [!Nota]
> Si est√° ejecutando Docker Desktop en macOS y ha establecido un tama√±o m√°s peque√±o para el disco virtual, puede encontrar el siguiente error:
>
>
> ```shell
> $ ./kind-load.sh
> ...
> Command Output: Error response from daemon: write /var/lib/docker/...
> /layer.tar: no space left on device
> ```
>
> Puede modificar el valor del l√≠mite del disco virtual en el men√∫ ``Settings -> Resources``.
>   ![L√≠mites del disco virtual de Docker Desktop de MacOS](imgs/macos-docker-desktop-virtual-disk-setting.png)

### Instalando NGINX Ingress Controller
Necesitamos NGINX Ingress Controller para enrutar el tr√°fico desde nuestra computadora port√°til a los servicios que se ejecutan dentro del cl√∫ster. NGINX Ingress Controller act√∫a como un enrutador que se ejecuta dentro del cl√∫ster pero tambi√©n est√° expuesto al mundo exterior.

```shell
kubectl apply -f https://raw.githubusercontent.com/kubernetes/ingress-nginx/release-1.8/deploy/static/provider/kind/deploy.yaml
```
Verifique que los pods dentro del `ingress-nginx` se hayan iniciado correctamente antes de continuar:

```shell
> kubectl get pods -n ingress-nginx
NAME                                        READY   STATUS      RESTARTS   AGE
ingress-nginx-admission-create-cflcl        0/1     Completed   0          62s
ingress-nginx-admission-patch-sb64q         0/1     Completed   0          62s
ingress-nginx-controller-5bb6b499dc-7chfm   0/1     Running     0          62s
```
Esto deber√≠a permitirte dirigir el tr√°fico desde `http://localhost` a los servicios dentro del cl√∫ster. Observa que para que KinD funcione de esta manera, proporcionamos par√°metros y etiquetas adicionales para el nodo Control Plane cuando creamos el cl√∫ster:

```yaml
nodes:
- role: control-plane
  kubeadmConfigPatches:
  - |
    kind: InitConfiguration
    nodeRegistration:
      kubeletExtraArgs:
        node-labels: "ingress-ready=true" #Esto permite que el Ingress Controller se instale en el nodo Control Plane
  extraPortMappings:
  - containerPort: 80 # Esto nos permite vincular el puerto 80 en el host local al Ingress Controller, para que pueda dirigir el tr√°fico a los servicios que se ejecutan dentro del cl√∫ster.
    hostPort: 80
    protocol: TCP
  - containerPort: 443
    hostPort: 443
    protocol: TCP
```
Una vez que tenemos nuestro cl√∫ster y nuestro Ingress Controller instalado y configurado, podemos seguir adelante para instalar nuestra aplicaci√≥n.

## Instalando la Aplicaci√≥n para Conferencia
Desde Helm 3.7+, podemos usar im√°genes OCI para publicar, descargar e instalar Helm Charts. Este enfoque utiliza Docker Hub como un registro de Helm Charts.

Para instalar la Aplicaci√≥n para Conferencia, solo necesitas ejecutar el siguiente comando:

```shell
helm install conference oci://docker.io/salaboy/conference-app --version v1.0.0
```
Tambi√©n puedes ejecutar el siguiente comando para ver los detalles del Helm Chart:

```shell
helm show all oci://docker.io/salaboy/conference-app --version v1.0.0
```
Verifica que todas los pods de la aplicaci√≥n est√©n en funcionamiento.

> [!NOTA]
> Ten en cuenta que si tu conexi√≥n a Internet es lenta, puede llevar un tiempo que la aplicaci√≥n se inicie. Dado que los servicios de la aplicaci√≥n dependen de algunos componentes de infraestructura (Redis, Kafka, PostgreSQL), estos componentes deben iniciarse y estar listos para que los servicios se conecten.
>
>Componentes como Kafka son bastante pesados, con alrededor de 335+ MB, PostgreSQL 88+ MB y Redis 35+ MB.

Eventualmente, deber√≠as ver algo como esto. Puede tomar unos minutos:

```shell
kubectl get pods
NAME                                                           READY   STATUS    RESTARTS      AGE
conference-agenda-service-deployment-7cc9f58875-k7s2x          1/1     Running   4 (45s ago)   2m2s
conference-c4p-service-deployment-54f754b67c-br9dg             1/1     Running   4 (65s ago)   2m2s
conference-frontend-deployment-74cf86495-jthgr                 1/1     Running   4 (56s ago)   2m2s
conference-kafka-0                                             1/1     Running   0             2m2s
conference-notifications-service-deployment-7cbcb8677b-rz8bf   1/1     Running   4 (47s ago)   2m2s
conference-postgresql-0                                        1/1     Running   0             2m2s
conference-redis-master-0                                      1/1     Running   0             2m2s
```

La columna RESTARTS del pod muestra que quiz√°s Kafka fue lento y el servicio se inicio primero por Kubernetes, por lo tanto, se reinicio para esperar a que Kafka estuviera listo.

Ahora puedes dirigir tu navegador a `http://localhost` para ver la aplicaci√≥n.

![conference app](imgs/conference-app-homepage.png)

## [Importante] Limpieza - ¬°¬°¬°Debes LEER!!!
Dado que la Aplicaci√≥n para Conferencia est√° instalando PostgreSQL, Redis y Kafka, si deseas eliminar e instalar la aplicaci√≥n nuevamente (lo cual haremos a medida que avancemos en las gu√≠as), debes asegurarte de eliminar los correspondientes PersistenceVolumeClaims (PVCs).

Estos PVCs son los vol√∫menes utilizados para almacenar los datos de las bases de datos y Kafka. No eliminar estos PVCs entre instalaciones har√° que los servicios utilicen credenciales antiguas para conectarse a las nuevas bases de datos provisionadas.

Puedes eliminar todos los PVCs enumer√°ndolos con:

```shell
kubectl get pvc
```

Deber√≠as ver:

```shell
NAME                                   STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS   AGE
data-conference-kafka-0                Bound    pvc-2c3ccdbe-a3a5-4ef1-a69a-2b1022818278   8Gi        RWO            standard       8m13s
data-conference-postgresql-0           Bound    pvc-efd1a785-e363-462d-8447-3e48c768ae33   8Gi        RWO            standard       8m13s
redis-data-conference-redis-master-0   Bound    pvc-5c2a96b1-b545-426d-b800-b8c71d073ca0   8Gi        RWO            standard       8m13s
```

Y luego eliminar con:
```shell
kubectl delete pvc  data-conference-kafka-0 data-conference-postgresql-0 redis-data-conference-redis-master-0
```
El nombre de los PVCs cambiar√° seg√∫n el nombre de la versi√≥n de Helm que usaste al instalar la gr√°fica.

Finalmente, si deseas deshacerte completamente del cl√∫ster KinD, puedes ejecutar:

```shell
kind delete clusters dev
```
-------

## Siguientes Pasos
Te recomiendo encarecidamente que te ensucies las manos con un cl√∫ster de Kubernetes real alojado en un proveedor de servicios en la nube. Puedes probar la mayor√≠a de los proveedores de servicios en la nube, ya que ofrecen una prueba gratuita donde puedes crear cl√∫steres de Kubernetes y ejecutar todos estos ejemplos [consulta este repositorio](https://github.com/learnk8s/free-kubernetes) para obtener m√°s informaci√≥n.

Si puedes crear un cl√∫ster en un proveedor de servicios en la nube y poner en marcha la aplicaci√≥n, obtendr√°s experiencia pr√°ctica en todos los temas tratados en el Cap√≠tulo 2.

## Resumen y Contribuci√≥n
En este breve tutorial, logramos instalar el esqueleto de la Aplicaci√≥n para Conferencia. Utilizaremos esta aplicaci√≥n como ejemplo a lo largo del resto de los cap√≠tulos. Aseg√∫rate de que esta aplicaci√≥n funcione para ti, ya que cubre lo b√°sico de usar e interactuar con un cl√∫ster de Kubernetes.

¬øQuieres mejorar este tutorial? Crea un [issue](https://github.com/salaboy/platforms-on-k8s/issues/new), env√≠ame un mensaje en [Twitter](https://twitter.com/salaboy) o env√≠a un [Pull Request](https://github.com/salaboy/platforms-on-k8s/compare).
